# ğŸ§  Member-QA: Rule-Based NLP Q&A System  
*Python Â· FastAPI Â· Docker Â· Google Cloud Run*

---

## ğŸ“‹ Overview
**Member-QA** is a small NLP microservice I built with **Python**, **FastAPI**, and **Docker**, then deployed on **Google Cloud Run**.  
It answers natural-language questions like:

- â€œWhen is **Layla Kawaguchi** going to Santorini?â€
- â€œWhen is **Sophia Al-Farsi** planning her trip to Paris?â€
- â€œWhat is **Armand Dupontâ€™s** phone number?â€
- â€œWhen is **Armand Dupont** going to Monaco?â€

Itâ€™s all rule-based â€” no large language models. I designed it to extract structured answers from member messages using regex and heuristics.

---

## âš™ï¸ Architecture
- **FastAPI backend** â†’ main app with `/ask`, `/health`, `/env`, `/debug/messages`
- **Regex-based NLP engine** â†’ identifies names, destinations, dates, phones, and restaurants
- **External Message API** â†’ pulls member messages from another Cloud Run service
- **Docker container** â†’ makes everything portable and consistent
- **Google Cloud Run** â†’ handles deployment, scaling, and authentication

---

## ğŸš€ Deployment

### Local
```bash
uvicorn main:app --reload
## How It Works

- **Extracts the userâ€™s name from the question.

- **Detects the intent (trip, phone, restaurant, cars).

- ** Fetches that userâ€™s messages from the data API.

- ** Runs regex + dateparser to find relevant info.

- ** Returns a short JSON answer, e.g.

{"answer": "Sophia Al-Farsi is planning the trip to Paris on 2025-05-09."}


Bonus 1: Design Notes (Alternatives I Considered)

- ** Using an LLM (like GPT-4) for intent detection and date parsing â€” faster to build but nondeterministic.

- ** Vector search or semantic embeddings for fuzzy retrieval â€” more flexible but overkill for this dataset.

- ** SpaCy NER â€” easier to maintain but required model training.

- ** Hybrid LLM + rules â€” probably the best balance long-term.

- ** Stuck with pure rules to keep it transparent and self-contained.

ğŸ“Š Bonus 2: Data Insights

While exploring the dataset:

- ** Some messages have relative dates (â€œthis Fridayâ€, â€œnext weekâ€) â†’ must be resolved using timestamps.

- ** Future timestamps exist â€” theyâ€™re planned trips, not errors.

- ** Contains PII like phone numbers and addresses in text.

- ** Mixed formatting styles (names with accents, various phone formats).

- ** A few clearly synthetic or test entries (e.g., fictional names/addresses).

- ** Overall, itâ€™s realistic data that just needs normalization and PII masking.

ğŸ§¾ Lessons Learned

- ** Building NLP from scratch is slow but helps you understand the logic behind LLMs.

- ** Time normalization with dateparser was key to making relative dates accurate.

- ** Cloud Run made deployment and scaling painless.

- ** Regex-based systems are fast and cheap â€” just not as â€œsmartâ€ as models.

If I expanded this, Iâ€™d add a small LLM fallback for questions my rules canâ€™t handle.
